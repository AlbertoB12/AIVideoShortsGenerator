{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertoB12/AIVideoShortsGenerator/blob/main/AIVideoShortsGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7iVH8PyZe5nx",
        "outputId": "13d9ff64-d828-4058-f5f9-5f3e98d3c0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the AI Video Generation script for social media!\n",
            "Installing and importing packages and resources.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "dask-cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-expr 1.1.19 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.12.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<!DOCTYPE policymap [\n",
            "  <!ELEMENT policymap (policy)*>\n",
            "  <!ATTLIST policymap xmlns CDATA #FIXED ''>\n",
            "  <!ELEMENT policy EMPTY>\n",
            "  <!ATTLIST policy xmlns CDATA #FIXED '' domain NMTOKEN #REQUIRED\n",
            "    name NMTOKEN #IMPLIED pattern CDATA #IMPLIED rights NMTOKEN #IMPLIED\n",
            "    stealth NMTOKEN #IMPLIED value CDATA #IMPLIED>\n",
            "]>\n",
            "<!--\n",
            "  Configure ImageMagick policies.\n",
            "\n",
            "  Domains include system, delegate, coder, filter, path, or resource.\n",
            "\n",
            "  Rights include none, read, write, execute and all.  Use | to combine them,\n",
            "  for example: \"read | write\" to permit read from, or write to, a path.\n",
            "\n",
            "  Use a glob expression as a pattern.\n",
            "\n",
            "  Suppose we do not want users to process MPEG video images:\n",
            "head: cannot open '/etc/ImageMagick-7/policy.xml' for reading: No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting preparation of the whole process.\n",
            "Chosen topics:\n",
            "Desired topic: 'Stoicism'.\n",
            "Safety topic: 'motivation'.\n",
            "\n",
            "Chosen directory to temporary save materials: '/content/drive/MyDrive/Documentos/Projects/Automatic videos/Material/'.\n",
            "\n",
            "Chosen voice model: tts_models/en/ljspeech/tacotron2-DDC.\n",
            "\n",
            "Chosen path for client.secrets.json for YouTube: /content/drive/MyDrive/Documentos/Projects/Automatic videos/client_secrets.json.\n",
            "Starting step 1: Script creation.\n",
            "Starting step 2: Video creation.\n",
            "No video results found for 'Stoicism' (even though request was OK).\n",
            "Video downloaded successfully to: /content/drive/MyDrive/Documentos/Projects/Automatic videos/Material/Video.mp4 (using topic: motivation)\n",
            "Starting step 3: Voiceover.\n",
            "Starting step 4: Video editing.\n",
            "Moviepy - Building video /content/drive/MyDrive/Documentos/Projects/Automatic videos/Material/final_video.mp4.\n",
            "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/drive/MyDrive/Documentos/Projects/Automatic videos/Material/final_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/drive/MyDrive/Documentos/Projects/Automatic videos/Material/final_video.mp4\n",
            "Starting step 5: Publishing.\n",
            "Generating video parameters.\n",
            "Uploading video.\n",
            "Uploading video to YouTube.\n",
            "An error occurred: 'could not locate runnable browser'\n",
            "Finalizing execution.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.kernel.disconnect()"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#### Script to automatically create AI videos for Youtube (Shorts), Instagram (Reels) and TikTok ####\n",
        "print(\"Welcome to the AI Video Generation script for social media!\")\n",
        "### Packages, imports and keys ###\n",
        "print(\"Installing and importing packages and resources.\")\n",
        "!pip install --upgrade -q pandas\n",
        "!pip install --upgrade -q networkx\n",
        "!pip install -q colab-xterm\n",
        "#!pip install -q ollama\n",
        "!pip install -q moviepy\n",
        "!pip install -q librosa\n",
        "!pip install -q soundfile\n",
        "!pip install -q edge-tts\n",
        "!apt-get install -y -qq pciutils > /dev/null 2>&1\n",
        "!apt-get install -y -qq lshw > /dev/null 2>&1\n",
        "!pip install -q TTS\n",
        "!pip install -q google-api-python-client\n",
        "!pip install -q google-auth-httplib2\n",
        "!pip install -q google-auth-oauthlib\n",
        "!pip install -q tweepy\n",
        "import psutil, requests, tempfile, torch, os, re, tweepy, time, random, warnings, librosa, soundfile, asyncio, nest_asyncio, edge_tts #, ollama\n",
        "!apt-get install -y imagemagick > /dev/null 2>&1\n",
        "!if [ -f /etc/ImageMagick-6/policy.xml ]; then sudo sed -i 's/rights=\"none\"/rights=\"read|write\"/g' /etc/ImageMagick-6/policy.xml; fi\n",
        "!if [ -f /etc/ImageMagick-7/policy.xml ]; then sudo sed -i 's/rights=\"none\"/rights=\"read|write\"/g' /etc/ImageMagick-7/policy.xml; fi\n",
        "!head -n 20 /etc/ImageMagick-6/policy.xml\n",
        "!head -n 20 /etc/ImageMagick-7/policy.xml\n",
        "os.environ['IMAGEMAGICK_BINARY'] = '/usr/bin/convert'\n",
        "import numpy as np\n",
        "from TTS.api import TTS\n",
        "from openai import OpenAI\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip, vfx\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from google.colab import runtime\n",
        "from IPython.display import Javascript\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nest_asyncio.apply()\n",
        "\"\"\"\n",
        "%load_ext colabxterm\n",
        "!curl -fsSL https://ollama.com/install.sh | bash\n",
        "!nohup ollama serve &\n",
        "!ollama pull llama3.1:8b\n",
        "\"\"\"\n",
        "## Pixabay keys\n",
        "pixabay_key = ''\n",
        "## X keys\n",
        "api_key = ''\n",
        "api_secret_key = ''\n",
        "access_token = ''\n",
        "access_token_secret = ''\n",
        "bearer_token = ''\n",
        "# Set up authentication with X API\n",
        "auth = tweepy.OAuth1UserHandler(\n",
        "    consumer_key=api_key,\n",
        "    consumer_secret=api_secret_key,\n",
        "    access_token=access_token,\n",
        "    access_token_secret=access_token_secret\n",
        ")\n",
        "# Authentication with OpenAI (Deepseek - OpenRouter)\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"\",\n",
        ")\n",
        "\n",
        "### Functions ###\n",
        "## def create_and_upload_video(desired_topic, standard_topic, saving_path, voice_model, client_secrets)\n",
        "# Main function to run the whole script\n",
        "# Gets strings with desired_topic, standard_topic, saving_path, voice_model, client_secrets\n",
        "# Generates script, gets suitable video, generates voiceover, edits video, publishes video\n",
        "def create_and_upload_video(desired_topic, standard_topic, saving_path, voice_model, client_secrets):\n",
        "  ## Step 1: Script creation\n",
        "  print(\"Starting step 1: Script creation.\")\n",
        "  # Generate script\n",
        "  script = generate_script(desired_topic)\n",
        "\n",
        "  ## Step 2: Video creation\n",
        "  print(\"Starting step 2: Video creation.\")\n",
        "  # Download and save video\n",
        "  get_video(desired_topic, standard_topic, saving_path)\n",
        "\n",
        "  ## Step 3: Voiceover\n",
        "  print(\"Starting step 3: Voiceover.\")\n",
        "  # Create and save voiceover\n",
        "  loop = asyncio.get_event_loop()\n",
        "  loop.run_until_complete(get_voiceover(script, saving_path, voice_model))\n",
        "\n",
        "  ## Step 4: Video editing\n",
        "  print(\"Starting step 4: Video editing.\")\n",
        "  # Edit video (merge video and voiceover, create subtitles)\n",
        "  edit_video(script, saving_path)\n",
        "\n",
        "  ## Step 5: Publishing\n",
        "  print(\"Starting step 5: Publishing.\")\n",
        "  # Generate parameters for the video: title, description and tags\n",
        "  print(\"Generating video parameters.\")\n",
        "  title, description, tags = get_video_parameters(script)\n",
        "  # Uploads\n",
        "  print(\"Uploading video.\")\n",
        "  upload_video(title, description, tags, saving_path)\n",
        "\n",
        "  ## Step 6: Finished!\n",
        "  print(\"All done!\")\n",
        "  # Disconnect from Google Colab\n",
        "  print(\"Finalizing execution.\")\n",
        "  display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "## def generate_script(desired_topic)\n",
        "# Function to generate script and topic for the video\n",
        "# Gets a str with the deseired topic\n",
        "# Returns str with script for the video\n",
        "def generate_script(desired_topic):\n",
        "  # If user introduced a topic\n",
        "  if desired_topic != \" \" or desired_topic != \"\":\n",
        "    # Generate script\n",
        "    script = client.chat.completions.create(\n",
        "      model=\"deepseek/deepseek-r1:free\",\n",
        "      messages=[\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": f\"\"\"Generate a concise, high-impact script that generates dopamine in users of social media for a short video with the topic '{desired_topic}'. Keep it between 80 and 120 words. The tone should be powerful, inspiring, and direct. Use short sentences and impactful phrasing. The script should encourage the values of the topic. No introduction, explanation, instructions for video or audio or ending indications, just the script as plain text, without asteriscs, etc..\"\"\"\n",
        "        }\n",
        "      ]\n",
        "    ).choices[0].message.content\n",
        "    script_clean = script.replace('\"', '')\n",
        "    # Return script\n",
        "    return script_clean\n",
        "  # If user did not introduce a topic\n",
        "  else:\n",
        "    print(\"No topic added! Please add a topic and start the execution again.\")\n",
        "    # Delete runtime\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "## def split_script(script, max_chars=200, min_chars=50)\n",
        "# Function to split script into chunks without breaking words or sentences\n",
        "# Gets str with script to be splitted and 2 int with max. und min. characters to form the chuncks\n",
        "# Returns str with chuncks of the script\n",
        "def split_script(script, max_chars=200, min_chars=50):\n",
        "  sentences = re.split(r'(?<=[.!?])\\s+', script)\n",
        "  chunks = []\n",
        "  current_chunk = \"\"\n",
        "\n",
        "  for sentence in sentences:\n",
        "    if len(current_chunk) + len(sentence) <= max_chars:\n",
        "      current_chunk += (\" \" if current_chunk else \"\") + sentence\n",
        "    else:\n",
        "      if len(current_chunk.strip()) >= min_chars:\n",
        "        chunks.append(current_chunk.strip())\n",
        "        current_chunk = sentence\n",
        "      else:\n",
        "        current_chunk += \" \" + sentence  # Merge short chunk\n",
        "\n",
        "  if current_chunk:\n",
        "    chunks.append(current_chunk.strip())\n",
        "\n",
        "  # Final pass: Merge very short chunks\n",
        "  final_chunks = []\n",
        "  for chunk in chunks:\n",
        "    if final_chunks and len(chunk) < min_chars:\n",
        "      final_chunks[-1] += \" \" + chunk\n",
        "    elif chunk:\n",
        "      final_chunks.append(chunk)\n",
        "\n",
        "  return final_chunks\n",
        "\n",
        "## def get_video(desired_topic, standard_topic, saving_path)\n",
        "# Funciton to download and save a video\n",
        "# Gets a str with the desired topic, a str with the safety topic and a str with the saving path\n",
        "# Saves the downloaded video\n",
        "def get_video(desired_topic, standard_topic, saving_path):\n",
        "    base_url = \"https://pixabay.com/api/videos/\"\n",
        "\n",
        "    def simple_quote(s):\n",
        "        return s.replace(\" \", \"+\")\n",
        "\n",
        "    topics_to_search = [desired_topic, standard_topic]\n",
        "\n",
        "    for topic in topics_to_search:\n",
        "        encoded_query = simple_quote(topic)\n",
        "        url = f\"{base_url}?key={pixabay_key}&q={encoded_query}\"\n",
        "\n",
        "        try:  # Add a try-except block for the request\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "\n",
        "            data = response.json()\n",
        "\n",
        "            if data[\"hits\"]:\n",
        "                selected_hit = random.choice(data[\"hits\"])\n",
        "                video_url = selected_hit[\"videos\"][\"medium\"][\"url\"]\n",
        "                video_path = f\"{saving_path}Video.mp4\"\n",
        "                with open(video_path, 'wb') as f:\n",
        "                    f.write(requests.get(video_url).content)\n",
        "                print(f\"Video downloaded successfully to: {video_path} (using topic: {topic})\")\n",
        "                return True\n",
        "\n",
        "            else:\n",
        "                print(f\"No video results found for '{topic}' (even though request was OK).\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e: # Catch request errors\n",
        "            print(f\"Error fetching data for '{topic}': {e}\")  # Print the actual error from requests\n",
        "            # Delete runtime\n",
        "            display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "\n",
        "        except (KeyError, ValueError) as e: # Handle JSON decoding errors\n",
        "            print(f\"Error parsing JSON response for '{topic}': {e}. Response content: {response.text}\")\n",
        "            # Delete runtime\n",
        "            display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "    print(\"No suitable videos found for any topic.\")\n",
        "    # Delete runtime\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "## async def get_voiceover(script, saving_path, voice_model)\n",
        "# Function to create and save voiceover for the video\n",
        "# Gets a str with the script for the voiceover, a str with the saving path and a str with the name of the voiceover model\n",
        "# Saves the created voiceover\n",
        "async def get_voiceover(script, saving_path, voice_model):\n",
        "  try:\n",
        "    # Get device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Initialize TTS model\n",
        "    #tts = TTS(model_name=voice_model, progress_bar=False).to(device)\n",
        "\n",
        "    # List to store generated audio file paths\n",
        "    audio_files = []\n",
        "\n",
        "    temp_path = f\"{saving_path}voice_part_0.wav\"\n",
        "    #tts.tts_to_file(text=script, file_path=temp_path)\n",
        "    tts = edge_tts.Communicate(script, voice=\"en-AU-WilliamNeural\")\n",
        "    await tts.save(temp_path)\n",
        "    audio_files.append(temp_path)\n",
        "\n",
        "    # Merge audio files if multiple parts exist\n",
        "    final_audio_path = f\"{saving_path}Voiceover.wav\"\n",
        "    if len(audio_files) > 1:\n",
        "      combined_audio = []\n",
        "      sample_rate = None\n",
        "\n",
        "      for audio_file in audio_files:\n",
        "        audio, sr = librosa.load(audio_file, sr=None)\n",
        "        if sample_rate is None:\n",
        "          sample_rate = sr\n",
        "        combined_audio.append(audio)\n",
        "        os.remove(audio_file)  # Clean up temporary files\n",
        "\n",
        "      # Concatenate audio and save\n",
        "      merged_audio = np.concatenate(combined_audio)\n",
        "      sf.write(final_audio_path, merged_audio, sample_rate)\n",
        "    else:\n",
        "      # If only one part, rename it as final output\n",
        "      os.rename(audio_files[0], final_audio_path)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "## def edit_video(script, saving_path):\n",
        "# Function to merge video and voiceover, creating the final video to be uploaded to social media\n",
        "# Access to video and voiceover\n",
        "# Gets str with script for the video and a str with the saving path\n",
        "# Creates the final video\n",
        "def edit_video(script, saving_path):\n",
        "  try:\n",
        "    # Load video and voiceover\n",
        "    video = VideoFileClip(f\"{saving_path}Video.mp4\")\n",
        "    voiceover = AudioFileClip(f\"{saving_path}Voiceover.wav\")\n",
        "  except Exception as e:\n",
        "    print(f\"Video or audio not found. An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "  # Get the duration of the video and the voiceover\n",
        "  try:\n",
        "    video_duration = video.duration\n",
        "    voiceover_duration = voiceover.duration\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "  # Adjust video duration to match voiceover\n",
        "  try:\n",
        "    if voiceover_duration < video_duration:\n",
        "      video = video.subclip(0, voiceover_duration)\n",
        "    elif voiceover_duration > video_duration:\n",
        "      loop_count = int(voiceover_duration // video_duration) + 1\n",
        "      video = video.fx(vfx.loop, n=loop_count).subclip(0, voiceover_duration)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "  # Split the script into meaningful parts\n",
        "  try:\n",
        "    script_parts = split_script(script, max_chars=200)\n",
        "    sentence_duration = voiceover_duration / len(script_parts)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "  try:\n",
        "    subtitles = []\n",
        "    for i, sentence in enumerate(script_parts):\n",
        "      start_time = i * sentence_duration\n",
        "      end_time = (i + 1) * sentence_duration\n",
        "      subtitles.append({\"text\": sentence, \"start\": start_time, \"end\": end_time})\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "  # Create text clips for each subtitle\n",
        "  try:\n",
        "    text_clips = []\n",
        "\n",
        "    for subtitle in subtitles:\n",
        "      # Calculate duration\n",
        "      duration = subtitle['end'] - subtitle['start']\n",
        "\n",
        "      # Bounce effect function - NOW IN THE MIDDLE\n",
        "      def bounce_effect(t):\n",
        "        return ('center', video.h / 2 - abs(10 * np.sin(2 * np.pi * t))) # Vertical center is video.h / 2\n",
        "\n",
        "      # Create main TextClip with enhanced style\n",
        "      txt_clip = TextClip(\n",
        "        subtitle['text'],\n",
        "        fontsize=75,\n",
        "        color='white',\n",
        "        stroke_color='black',\n",
        "        stroke_width=4,\n",
        "        align='center',\n",
        "        method='caption',\n",
        "        size=(video.w * 0.9, None)\n",
        "      ).set_duration(duration).set_position(bounce_effect).fadein(0.2).fadeout(0.2)\n",
        "\n",
        "      # Create shadow effect (optional)\n",
        "      shadow = txt_clip.set_opacity(0.5).set_position((\"center\", video.h / 2 + 50)) # Shadow a bit below center\n",
        "\n",
        "      # Combine shadow and text\n",
        "      final_txt_clip = CompositeVideoClip([shadow, txt_clip]) # Or just use txt_clip alone: final_txt_clip = txt_clip\n",
        "\n",
        "      # Set subtitle start time\n",
        "      final_txt_clip = final_txt_clip.set_start(subtitle['start'])\n",
        "\n",
        "      text_clips.append(final_txt_clip)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "  # Combine the video and subtitles\n",
        "  try:\n",
        "    video_with_subtitles = CompositeVideoClip([video] + text_clips)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "  # Set the audio of the video to the voiceover\n",
        "  try:\n",
        "    final_video = video_with_subtitles.set_audio(voiceover)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "  # Export the final video\n",
        "  try:\n",
        "    final_video.write_videofile(f\"{saving_path}final_video.mp4\", codec=\"libx264\", audio_codec=\"aac\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: '{e}'\")\n",
        "    print(\"Finalizing execution.\")\n",
        "    display(Javascript('google.colab.kernel.disconnect()'))\n",
        "\n",
        "## def generate_video_title(script)\n",
        "# Function to generate a title for the video before uploading it to social media\n",
        "# Gets str with script of the video\n",
        "# Returns str with title for the video\n",
        "def generate_video_title(script):\n",
        "  # Generate title\n",
        "  title = client.chat.completions.create(\n",
        "    model=\"deepseek/deepseek-r1:free\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Generate an engaging and attention-grabbing title for a social media video based on the following script: '{script}'.\n",
        "The title should be concise, impactful, and relevant to the content, suitable for platforms like YouTube, Instagram, and TikTok. It should also generate dopamine in the users. Do not generate introductions or explanations, just the title.\"\"\"\n",
        "      }\n",
        "    ]\n",
        "  ).choices[0].message.content\n",
        "  return title\n",
        "\n",
        "## def generate_video_description(script)\n",
        "# Function to generate a description for the video before uploading it to social media\n",
        "# Gets str with script of the video\n",
        "# Returns str with description for the video\n",
        "def generate_video_description(script):\n",
        "  # Generate description\n",
        "  description = client.chat.completions.create(\n",
        "    model=\"deepseek/deepseek-r1:free\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Generate an engaging and attention-grabbing description for a social media video based on the following script: '{script}'.\n",
        "The description should be concise, impactful, and relevant to the content, suitable for platforms like YouTube, Instagram, and TikTok. It should also generate dopamine in the users. Do not generate introductions or explanations, just the description.\"\"\"\n",
        "      }\n",
        "    ]\n",
        "  ).choices[0].message.content\n",
        "  return description\n",
        "\n",
        "## def generate_video_tags(script)\n",
        "# Function to generate tags for the video before uploading it to social media\n",
        "# Gets str with script of the video\n",
        "# Returns str with tags for the video\n",
        "def generate_video_tags(script):\n",
        "  # Generate tags\n",
        "  tags = client.chat.completions.create(\n",
        "    model=\"deepseek/deepseek-r1:free\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Generate an engaging and attention-grabbing title for a social media video based on the following script: '{script}'.\n",
        "The title should be concise, impactful, and relevant to the content, suitable for platforms like YouTube, Instagram, and TikTok. It should also generate dopamine in the users. Do not generate introductions or explanations, just the title.\"\"\"\n",
        "      }\n",
        "    ]\n",
        "  ).choices[0].message.content\n",
        "  return tags\n",
        "\n",
        "## def get_video_parameters (script)\n",
        "# Function to generate once in the same function the title, description and tags for the video\n",
        "# Gets str with the script of the video\n",
        "# Returns 3 str with title, description and tags for the video\n",
        "def get_video_parameters(script):\n",
        "  # Generate title\n",
        "  title = generate_video_title(script)\n",
        "  # Generate description\n",
        "  description = generate_video_description(script)\n",
        "  # Generate tags\n",
        "  tags = generate_video_tags(script)\n",
        "\n",
        "  return title, description, tags\n",
        "\n",
        "## def upload_youtube(title, description, tags, saving_path)\n",
        "# Function to upload video to YouTube\n",
        "# Gets strings with title, description, tags and saving path of the video\n",
        "# Uploads the video to YouTube\n",
        "def upload_youtube(title, description, tags, saving_path):\n",
        "  print(\"Uploading video to YouTube.\")\n",
        "  # Set up authentication\n",
        "  scopes = ['https://www.googleapis.com/auth/youtube.upload']\n",
        "  flow = InstalledAppFlow.from_client_secrets_file(client_secrets, scopes)\n",
        "  credentials = flow.run_local_server(port=0)\n",
        "\n",
        "  # Build the YouTube API client\n",
        "  youtube = build('youtube', 'v3', credentials=credentials)\n",
        "\n",
        "  title = f\"{title} #Shorts\"\n",
        "\n",
        "  # Create a request to upload the Short\n",
        "  request = youtube.videos().insert(\n",
        "    part=\"snippet,status\",\n",
        "    body={\n",
        "      \"snippet\": {\n",
        "      \"title\": title,\n",
        "      \"description\": f\"{description} Video from: https://pixabay.com/\",\n",
        "      \"tags\": tags,\n",
        "      \"categoryId\": '27',\n",
        "    },\n",
        "    \"status\": {\n",
        "      \"privacyStatus\": \"public\",\n",
        "    }\n",
        "    },\n",
        "    media_body=MediaFileUpload(f\"{saving_path}final_video.mp4\", chunksize=-1, resumable=True)\n",
        "  )\n",
        "\n",
        "  # Execute the request\n",
        "  response = request.execute()\n",
        "  print(f\"YouTube upload successful! Video ID: {response['id']}\")\n",
        "\n",
        "## upload_x(title, description, tags, saving_path)\n",
        "# Function to upload video to X\n",
        "# Gets strings with title, tags and saving path of the video\n",
        "# Uploads the video to X\n",
        "def upload_x(title, tags, saving_path):\n",
        "  print(\"Uploading video to X.\")\n",
        "  # Create API object\n",
        "  api = tweepy.API(auth)\n",
        "\n",
        "  # Step 1: Upload the video to X as media\n",
        "  media = api.media_upload(f\"{saving_path}final_video.mp4\")\n",
        "\n",
        "  # Step 2: Post a tweet with the uploaded video\n",
        "  # Text that will accompany the video\n",
        "  status = f\"{title} {tags} Video from: https://pixabay.com/\"\n",
        "  # Upload\n",
        "  tweet = api.update_status(status=status, media_ids=[media.media_id])\n",
        "  print(f\"Successfully uploaded video to X! Tweet ID: {tweet.id}\")\n",
        "\n",
        "def upload_facebook(title, description, tags, saving_path):\n",
        "  print(\"Uploading video to Facebook.\")\n",
        "  # Will be addded in the future\n",
        "\n",
        "def upload_instagram(title, description, tags, saving_path):\n",
        "  print(\"Uploading video to Instagram.\")\n",
        "  # Will be addded in the future\n",
        "\n",
        "def upload_tiktok(title, description, tags, saving_path):\n",
        "  print(\"Uploading video to TikTok.\")\n",
        "  # Will be addded in the future\n",
        "\n",
        "## def upload_video(title, description, tags, saving_path)\n",
        "# Function to upload the final video to YouTube, TikTok, Instagram and X\n",
        "# Gets a str with the title of the video, a str with the description of the video, a str with the tags and a str with the saving path\n",
        "# Uploads the video to the different platforms\n",
        "def upload_video(title, description, tags, saving_path):\n",
        "  # Upload to YouTube\n",
        "  upload_youtube(title, description, tags, saving_path)\n",
        "\n",
        "  # Upload to X\n",
        "  upload_x(title, tags, saving_path)\n",
        "\n",
        "  # Upload to Facebook\n",
        "  #upload_facebook(title, description, tags, saving_path)\n",
        "\n",
        "  # Upload to Instagram\n",
        "  #upload_instagram(title, description, tags, saving_path)\n",
        "\n",
        "  # Upload to TikTok\n",
        "  #upload_tiktok(title, description, tags, saving_path)\n",
        "\n",
        "\n",
        "### Code ###\n",
        "try:\n",
        "  ## Preparation\n",
        "  print(\"Starting preparation of the whole process.\")\n",
        "  # Variables to decide, if desired, the topic and 'safety' topic of the video\n",
        "  desired_topic = \"\"  # If desired, add a topic for the video. If not, leave as it is -> \" \"\n",
        "  standard_topic = \"\"  # Standard topic for searching a video, if the topic generated by the AI model doesn't result on a video  # Always has to have a value\n",
        "  saving_path = \"\"  # Path to temporary save materials\n",
        "  voice_model = 'tts_models/en/ljspeech/tacotron2-DDC'  # Desired voice model\n",
        "  client_secrets = ''  # Path to the client_secrets.json for YouTube-upload\n",
        "  print(f\"Chosen topics:\\nDesired topic: '{desired_topic}'.\\nSafety topic: '{standard_topic}'.\\n\\nChosen directory to temporary save materials: '{saving_path}'.\\n\\nChosen voice model: {voice_model}.\\n\\nChosen path for client.secrets.json for YouTube: {client_secrets}.\")\n",
        "  # Run main function with all sub-functions to create and upload video\n",
        "  for execution in range(1):  # Change number with number of videos you want to generate\n",
        "    create_and_upload_video(desired_topic, standard_topic, saving_path, voice_model, client_secrets)\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: '{e}'\")\n",
        "  print(\"Finalizing execution.\")\n",
        "  # Disconnect from Google Colab\n",
        "  display(Javascript('google.colab.kernel.disconnect()'))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}